{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the same as DataExtractionProcessing notebook, but it was used for the case of having the data in one file only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import urllib2\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from scipy import misc\n",
    "from time import strftime,strptime\n",
    "import re\n",
    "import math\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note 1: We can use the Classes instead of reimplementing the functions.\n",
    "##### Note 2: You can use SQLAlchemy instead of generating MySQL queries from a dataframe to insert data into a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getimage(url, full_name):\n",
    "    \"\"\"\n",
    "    Downloads the image and returns and object of that image.\n",
    "    url: image url.\n",
    "    full_name: path with file name to save the image.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(full_name):\n",
    "        return mpimg.imread(full_name)\n",
    "    \n",
    "    try:\n",
    "        f = urllib2.urlopen(url)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    data = f.read()\n",
    "    with open(full_name, \"wb\") as code:\n",
    "        code.write(data)\n",
    "    return mpimg.imread(full_name)\n",
    "\n",
    "def getallimages(panda_name, column_name):\n",
    "    \"\"\"\n",
    "    Downloads a group of images from a panda dataframe.\n",
    "    panda_name: dataframe object.\n",
    "    column_name: column containing the url.\n",
    "    \"\"\"\n",
    "    downloaded_images = []\n",
    "    for row in panda_name.loc[panda_name[column_name].notnull(),column_name]:\n",
    "        for image in row:\n",
    "            img = getimage(image[column_name],image[column_name].split('/')[-1])\n",
    "            if not(img is None):\n",
    "                downloaded_images.append(img)\n",
    "    return downloaded_images\n",
    "\n",
    "def klout_getId(screen_name):\n",
    "    \"\"\"\n",
    "    Gets user's klout id if exists.\n",
    "    screenname: user\n",
    "    \"\"\"\n",
    "    url = 'http://api.klout.com/v2/identity.json/twitter?screenName={0}&key=memp3ncn4qvp6c8guzjcc8dp'.format(screen_name)    \n",
    "    try:\n",
    "        return json.load(urllib2.urlopen(url))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def klout_getScore(klout_id):\n",
    "    \"\"\"\n",
    "    Gets user's klout score if exists.\n",
    "    \n",
    "    klout_id: user's klout id.\n",
    "    \"\"\"\n",
    "    url = 'http://api.klout.com/v2/user.json/{0}/score?key=memp3ncn4qvp6c8guzjcc8dp'.format(kloutId)\n",
    "    try:\n",
    "        return json.load(urllib2.urlopen(url))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def extractImageUrl(cell):\n",
    "    \"\"\"\n",
    "    Gets user's klout id if exists.\n",
    "    cell: extracts tweets image url out of media object.\n",
    "    \"\"\"\n",
    "    if cell is None:\n",
    "        return None\n",
    "    return cell[0]['media_url']\n",
    "\n",
    "def convertDTToDB(cell):\n",
    "    \"\"\"\n",
    "    Converts the time to a MySQL-friendly url.\n",
    "    cell: datetime string.\n",
    "    \"\"\"\n",
    "    return strftime('%Y-%m-%d %H:%M:%S', strptime(cell,'%Y-%m-%dT%H:%M:%S.000Z'))\n",
    "def getOldId(cell):\n",
    "    \"\"\"\n",
    "    Get's the ID of tweet or user from gnip format.\n",
    "    cell: string contatining id.\n",
    "    \"\"\"\n",
    "    return cell.split(':')[2]\n",
    "\n",
    "def normalizeTweetText(text):\n",
    "    \"\"\"\n",
    "    Normalize tweet text to a MySQL-friendly format.\n",
    "    text: text string.\n",
    "    \"\"\"\n",
    "    if text is None or type(text) is float:\n",
    "        return None\n",
    "    return re.sub(r'[^\\w#:@/\\.\\-\\,]', ' ', text)\n",
    "\n",
    "## Note that if we may put NULL for any of the attributes\n",
    "## we should remove the single quotation marks from around them.\n",
    "def ensureDBNull(cell):\n",
    "    return 'NULL' if cell is None else (\"'\" + cell + \"'\")\n",
    "\n",
    "def getTweetsInsertQuery(tweets):\n",
    "    \"\"\"\n",
    "    Generate insert queries for tweet objects.\n",
    "    tweets: tweets dataframe.\n",
    "    \"\"\"\n",
    "    query = \"\"\n",
    "    for tweet in tweets:\n",
    "        temp = \"REPLACE INTO tweet VALUES('{0}', '{1}', '{2}', '{3}', {4}, '{5}', {6}, {7}, {8});\\n\".format(tweet[0],\n",
    "                                     tweet[1],\n",
    "                                     tweet[2],\n",
    "                                     tweet[3],\n",
    "                                     ensureDBNull(tweet[4]),\n",
    "                                     tweet[5],\n",
    "                                     ensureDBNull(tweet[6]),\n",
    "                                     ensureDBNull(tweet[7]),\n",
    "                                     ensureDBNull(tweet[8]))\n",
    "        \n",
    "        query = \"{0}{1}\".format(query, temp)                         \n",
    "    return query\n",
    "\n",
    "def getUsersInsertQuery(users):\n",
    "    \"\"\"\n",
    "    Generate insert queries for user objects.\n",
    "    users: users dataframe.\n",
    "    \"\"\"\n",
    "    query = \"\"\n",
    "    for user in users:\n",
    "        temp = \"REPLACE INTO user VALUES('{0}', '{1}', {2}, {3}, \\\n",
    "          '{4}', '{5}', '{6}', {7}, '{8}');\\n\".format(user[0],\n",
    "                                                   user[1],\n",
    "                                                   ensureDBNull(user[2]),\n",
    "                                                   user[3],\n",
    "                                                   user[4],\n",
    "                                                   user[5],\n",
    "                                                   user[6],\n",
    "                                                   ensureDBNull(user[7]),\n",
    "                                                   user[8])\n",
    "\n",
    "        query = \"{0}{1}\".format(query, temp)                \n",
    "    return query\n",
    "\n",
    "def getPlacesInsertQuery(places):\n",
    "    \"\"\"\n",
    "    Generate insert queries for place objects.\n",
    "    places: tweets dataframe.\n",
    "    \"\"\"\n",
    "    query = \"\"\n",
    "    for place in places:\n",
    "        temp = \"REPLACE INTO place VALUES ('{0}', '{1}', '{2}', '{3}');\\n\".format(place[0],\n",
    "                                                     place[1],\n",
    "                                                     place[2],\n",
    "                                                     place[3])\n",
    "\n",
    "        query = \"{0}{1}\".format(query, temp)\n",
    "    return query\n",
    "\n",
    "\n",
    "def convertNanToNone(text):\n",
    "    \"\"\"\n",
    "    Change any 'nan' string to None.\n",
    "    text: text string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if str(text) == 'nan':\n",
    "            return None\n",
    "    except:\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "def listToStr(cell):\n",
    "    \"\"\"\n",
    "    Convert a list of strings to one string holds all of them.\n",
    "    cell: list of strings.\n",
    "    \"\"\"\n",
    "    if cell is None:\n",
    "        return None\n",
    "    mystr = \"\";\n",
    "    for i in cell:\n",
    "        try:\n",
    "            mystr = mystr + \",\" + str(i)\n",
    "        except:\n",
    "            print i\n",
    "    mystr = \"[{0}]\".format(mystr[1:])\n",
    "    return mystr\n",
    "def getDBInstance(host, user, password, db):\n",
    "    \"\"\"\n",
    "    Returns a mysql db object.\n",
    "    Parameters are obvious.\n",
    "    \"\"\"\n",
    "    return MySQLdb.connect(host,\n",
    "                         user,\n",
    "                         password,\n",
    "                         db)\n",
    "def extractHashTags(hashTags):\n",
    "    \"\"\"\n",
    "    Extract hashtags out of hashtag objects list.\n",
    "    hashTags: hashtags list.\n",
    "    \"\"\"\n",
    "    if hashTags is None or hashTags == []:\n",
    "        return None\n",
    "    mylist = ''\n",
    "    for hashtag in hashTags:\n",
    "        mylist = mylist + ',' + hashtag['text']\n",
    "    return mylist[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = getDBInstance('geotwitter.uncg.edu', 'root', 'vJnVubg49U', 'geotwitter')\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the data and put it in a panda dataframe\n",
    "myjson = []\n",
    "myfile = open(\"/media/saed/Data/ubuntu data/data.json\", 'r')\n",
    "for i in range(10000):\n",
    "    myjson.append(json.loads(myfile.readline()))\n",
    "myfile.close()\n",
    "mypanda = pd.io.json.json_normalize(myjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mypanda.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing the needed columns, removing duplicates,\n",
    "## remove all-null rows and renaming the columns\n",
    "mydata = mydata.drop_duplicates(subset = ['id_str'])\n",
    "mydata = mydata[['id_str','created_at','text','coordinates.coordinates',\n",
    "                  'entities.media','lang','user.id_str','user.screen_name',\n",
    "                  'user.location','user.verified','user.followers_count','user.friends_count',\n",
    "                  'user.statuses_count','user.created_at','place.id','place.full_name',\n",
    "                  'place.country_code','place.bounding_box.coordinates']]\n",
    "mydata = mydata.dropna(axis = 0, how = 'all')\n",
    "mydata = mydata.loc[mydata['id_str'].notnull()]\n",
    "mydata = mydata.reset_index(drop = True)\n",
    "mydata = mydata.rename(index=str, columns={'id_str' : 'tweet.id', 'coordinates.coordinates' : 'tweet.coordinates',\n",
    "                                  'created_at' : 'tweet.created_at', 'text' : 'tweet.text', 'lang' : 'tweet.lang',\n",
    "                                  'entities.media' : 'tweet.media', 'user.id_str' : 'user.id',\n",
    "                                  'place.full_name' : 'place.name', 'place.country_code' : 'place.country',\n",
    "                                  'place.bounding_box.coordinates' : 'place.polygon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Normalizing data representation a little\n",
    "mydata = mydata.applymap(convertNanToNone)\n",
    "mydata['tweet.created_at'] = mydata['tweet.created_at'].apply(convertDTToDB)\n",
    "mydata['user.created_at'] = mydata['user.created_at'].apply(convertDTToDB)\n",
    "mydata['tweet.coordinates'] = mydata['tweet.coordinates'].apply(convertNanToNone)\n",
    "mydata['tweet.text'] = mydata['tweet.text'].apply(normalizeTweetText)\n",
    "mydata['user.location'] = mydata['user.location'].apply(normalizeTweetText)\n",
    "mydata['tweet.media'] = mydata['tweet.media'].apply(extractImageUrl)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = mydata[['tweet.id','tweet.created_at','tweet.text','user.id','tweet.coordinates','place.id','tweet.media','tweet.lang']]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mycursor.execute(getTweetsInsertQuery(tweets.values))\n",
    "    mydb.commit()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = mydata[['user.id','user.screen_name','user.location','user.verified','user.followers_count','user.friends_count','user.statuses_count','user.created_at']]\n",
    "users = users.drop_duplicates(subset = ['user.id'])\n",
    "users['klout_score'] = [0.0] * len(users)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mycursor.execute(getUsersInsertQuery(users.values))\n",
    "    mydb.commit()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "places = mydata[['place.id','place.name','place.country','place.polygon']]\n",
    "places = places.drop_duplicates(subset = ['place.id'])\n",
    "places['place.name'] = places['place.name'].apply(normalizeTweetText)\n",
    "places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mycursor.execute(getPlacesInsertQuery(places.values))\n",
    "    mydb.commit()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
